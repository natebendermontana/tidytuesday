---
 title: "Board Game Reviews"
output: html_document
date: "2024-10-25"
---

## Lasso Regression

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(tidymodels)
library(broom)
library(glmnet)
library(tidytext)
library(Matrix)

theme_set(theme_light())
```

```{r}
board_games_raw <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-12/board_games.csv")

holdout_set <- board_games_raw %>% 
  filter(game_id %% 5 == 0)

board_games <- board_games_raw %>% 
  filter(game_id %% 5 != 0)

```

## EDA 
```{r}
board_games %>% 
  count(publisher, sort=T)

board_games %>% 
  filter(users_rated >= 200) %>% 
  ggplot(aes(average_rating))+
  geom_histogram()

board_games %>% 
  count(year_published) %>% 
  arrange(desc(year_published)) %>% 
  ggplot(aes(year_published, n)) +
  geom_line()


```

```{r}
board_games %>% 
  filter(max_playtime >5, max_playtime < 1000) %>%
  ggplot(aes(max_playtime / 60))+
  geom_histogram(binwidth = .25) + 
  scale_x_log10(breaks = 2^seq(-2,4))

```

## Categorical vars

```{r}
categorical_variables <- board_games %>% 
  select(game_id, name, family, category, artist, designer) %>% 
  gather(type, value, -game_id, -name) %>% 
  filter(!is.na(value)) %>% 
  separate_rows(value, sep = ",") %>% 
  arrange(game_id)

categorical_counts <- categorical_variables %>% 
  count(type, value, sort = T)

categorical_counts %>% 
  group_by(type) %>% 
  top_n(20, n) %>% 
  ungroup() %>% 
  mutate(value = fct_reorder(value, n)) %>% 
  ggplot(aes(value, n, fill = type)) + 
  geom_col() + 
  coord_flip() + 
  scale_x_reordered() + 
  facet_wrap(~ type, scales = "free_y")

```


```{r}
board_games %>% 
  group_by(decade = 10 * (year_published %/% 10)) %>% 
  summarize(average_rating = mean(average_rating)) %>% 
  ggplot(aes(decade, average_rating)) + 
  geom_line()
```


```{r}
lm(average_rating ~
     log2(max_players + 1) +
     log2(max_playtime + 1) +
     year_published, board_games) %>% 
  tidy()
```

```{r}
board_games %>% 
  inner_join(categorical_variables, by = c("game_id", "name")) %>% 
  select(type, value, average_rating) %>% 
  group_by(type, value) %>% 
  summarize(games = n(),
            average_rating = mean(average_rating)) %>% 
  arrange(desc(games))

```

# pulling type and value together to create a list of features that will be useful for ML
```{r}

non_categorical_features <- board_games %>% 
  transmute(game_id, name, 
            year = year_published - 1950, 
            log2_max_players = log2(max_players +1),
            log2_max_playtime = log2(max_playtime + 1)
            ) %>% 
  gather(feature, value, -game_id, -name)
  

features <- categorical_variables %>% 
  unite(feature, type, value, sep = ": ") %>% 
  add_count(feature) %>% 
  filter(n >= 20) %>% 
  mutate(value = 1) %>% 
  bind_rows(non_categorical_features)

# predictor

feature_matrix <- features %>% 
  cast_sparse(game_id, feature, value)


# response variable
ratings <- board_games$average_rating[match(rownames(feature_matrix), board_games$game_id)]

cv_lasso <- cv.glmnet(feature_matrix, ratings)

plot(cv_lasso)

```

```{r}
cv_lasso$glmnet.fit %>% 
  tidy() %>% 
  filter(lambda == cv_lasso$lambda.1se) %>% 
  arrange(desc(estimate)) %>% 
  filter(term != "(Intercept)") %>% 
  top_n(30, abs(estimate)) %>% 
  group_by(direction = ifelse(estimate <0, "Negative", "Positive")) %>% 
  mutate(term = fct_reorder(term, estimate)) %>% 
  ggplot(aes(term, estimate, fill = direction)) +
  geom_col() + 
  coord_flip()+
  labs(title = "Largest coefficients in our Lasso regression model",
       x = "",
       y = "Coefficient")
```


## My additional exploration beyond the tutorial 
### Testing the model
```{r}
# Step 2: Filter and prepare the holdout feature data as before
holdout_categorical_features <- holdout_set %>%
  select(game_id, name, family, category, artist, designer) %>%
  gather(type, value, -game_id, -name) %>%
  filter(!is.na(value)) %>%
  separate_rows(value, sep = ",") %>%
  unite(feature, type, value, sep = ": ") %>%
  add_count(feature) %>%
  filter(n >= 20) %>%
  mutate(value = 1)

holdout_non_categorical_features <- holdout_set %>%
  transmute(
    game_id, name, 
    year = year_published - 1950, 
    log2_max_players = log2(max_players + 1),
    log2_max_playtime = log2(max_playtime + 1)
  ) %>%
  gather(feature, value, -game_id, -name)


# Combine the categorical and non-categorical features for the holdout set
holdout_features <- bind_rows(holdout_categorical_features, holdout_non_categorical_features)

# Step 3: Create a sparse matrix for the holdout features
holdout_feature_matrix <- holdout_features %>%
  filter(feature %in% colnames(feature_matrix)) %>% # Only include features present in the training set
  cast_sparse(game_id, feature, value)

# Step 4: Add missing columns (features) from the training set to the holdout matrix with values set to zero
missing_features <- setdiff(colnames(feature_matrix), colnames(holdout_feature_matrix))
holdout_feature_matrix <- cbind(holdout_feature_matrix, Matrix(0, nrow = nrow(holdout_feature_matrix), ncol = length(missing_features)))
colnames(holdout_feature_matrix) <- colnames(feature_matrix)

# Step 2: Predict ratings for the holdout set
predicted_ratings <- predict(cv_lasso, newx = holdout_feature_matrix, s = "lambda.1se")

# Step 3: Calculate evaluation metrics
# Extract actual ratings for holdout games
actual_ratings <- holdout_set$average_rating[match(rownames(holdout_feature_matrix), holdout_set$game_id)]

# Calculate MAE, MSE, and R-squared
mae <- mean(abs(predicted_ratings - actual_ratings))
mse <- mean((predicted_ratings - actual_ratings)^2)
rsq <- 1 - sum((predicted_ratings - actual_ratings)^2) / sum((actual_ratings - mean(actual_ratings))^2)

# Print the results
cat("Mean Absolute Error (MAE):", mae, "\n")
cat("Mean Squared Error (MSE):", mse, "\n")
cat("R-squared:", rsq, "\n")

```


```{r}
# Step 1: Generate predictions on the holdout set
predicted_ratings <- predict(cv_lasso, newx = holdout_feature_matrix, s = "lambda.1se")

# Step 2: Prepare a data frame with actual and predicted ratings, and calculate residuals
performance_data <- data.frame(
  actual = actual_ratings,
  predicted = as.vector(predicted_ratings)
) %>%
  mutate(residual = predicted - actual)  # Calculate residual

ggplot(performance_data, aes(x = actual, y = predicted, color = residual)) +
  geom_point(alpha = 1) +
  #geom_abline(intercept = 0, slope = 1, color = "black", linetype = "dashed") +
  scale_color_gradient2(low = "blue", mid = "grey", high = "red", midpoint = 0) +
  labs(
    title = "Actual vs. Predicted Board Game Ratings",
    x = "Actual Rating",
    y = "Predicted Rating",
    color = "Residual\n(Predicted - Actual)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )

```





